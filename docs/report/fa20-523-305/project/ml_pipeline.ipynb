{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os as os\n",
    "from time import time\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder, LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Classes for Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load_Data(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        self.features = features\n",
    "        self.weather_dir = ''\n",
    "        self.soil_dir = ''\n",
    "        self.drop_columns = ['STATION', 'NAME', 'LATITUDE', 'LONGITUDE', 'ELEVATION', 'AWND_ATTRIBUTES', 'PGTM_ATTRIBUTES', \n",
    "                             'PSUN', 'PSUN_ATTRIBUTES', 'SNOW', 'SNOW_ATTRIBUTES', 'SNWD', 'SNWD_ATTRIBUTES', 'TAVG',\n",
    "                             'TAVG_ATTRIBUTES', 'TMAX_ATTRIBUTES', 'TMIN_ATTRIBUTES', 'TSUN', 'TSUN_ATTRIBUTES', 'WDF2_ATTRIBUTES', \n",
    "                             'WDF5_ATTRIBUTES', 'WSF2_ATTRIBUTES','WSF5_ATTRIBUTES', 'WT01_ATTRIBUTES', 'WT02_ATTRIBUTES', \n",
    "                             'WT03_ATTRIBUTES', 'WT06_ATTRIBUTES', 'WT08_ATTRIBUTES', 'PRCP_ATTRIBUTES']\n",
    "        \n",
    "    def fit(self, w_dir, s_dir):\n",
    "        self.weather_dir = w_dir\n",
    "        self.soil_dir = s_dir\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        #Aggregate all 43 files into one file\n",
    "        file_list = os.listdir(self.soil_dir)\n",
    "        agg_data = pd.DataFrame()\n",
    "        for file in file_list:\n",
    "            path = self.soil_dir + file\n",
    "            curr_data = pd.read_csv(path, sep='\\t')\n",
    "            agg_data = agg_data.append(curr_data)\n",
    "        \n",
    "        #Drop rows with only NAs for measurement values\n",
    "        soil = agg_data.dropna(thresh=10)\n",
    "        \n",
    "        #Import weather files and drop unnessecary fields\n",
    "        weather = pd.read_csv(self.weather_dir)\n",
    "        drop_cols = list(set(weather.columns).intersection(self.drop_columns))\n",
    "        weather = weather.drop(columns = self.drop_columns)\n",
    "        \n",
    "        #Convert both files to use same datetime\n",
    "        soil['Date'] = pd.to_datetime(soil['Date'])\n",
    "        weather['DATE'] = pd.to_datetime(weather['DATE'])\n",
    "        \n",
    "        #Join previous 10 days weather to moisture readings\n",
    "        for i in range(0, 11):\n",
    "            weather_new = weather.add_suffix('_' + str(i))\n",
    "            soil = soil.merge(weather_new, how = 'left', left_on = 'Date', right_on = weather['DATE'] - pd.DateOffset(i * -1))\n",
    "        \n",
    "        #Setting location to category for faster processing\n",
    "        soil['Location'] = soil['Location'].astype('category')\n",
    "            \n",
    "        return soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Engineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        #Add categorical feature that simply stores if it rained that day or not\n",
    "        for i in range(11):\n",
    "            col_name = 'PRCP_' + str(i)\n",
    "            rain_y_n_name = 'RAIN_Y_N_' + str(i)\n",
    "            X[rain_y_n_name] = np.nan\n",
    "            X[rain_y_n_name].loc[X[col_name] > 0] = 1\n",
    "            X[rain_y_n_name].loc[X[col_name] == 0] = 0\n",
    "            X[rain_y_n_name] = X[rain_y_n_name].astype('category')\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convert_Date(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names = None):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X['Date'] = pd.to_timedelta(X['Date']).dt.total_seconds().astype(int)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Pipeline That Uses Data Processing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "soil_file_dir = 'data/soil/'\n",
    "weather_file_dir = 'data/weather/weather_data.csv'\n",
    "x = 0\n",
    "\n",
    "pre_work_pipeline = Pipeline([\n",
    "    ('prework', Load_Data()),\n",
    "    ('features', Feature_Engineer())\n",
    "])\n",
    "\n",
    "pre_work_pipeline.fit(weather_file_dir, soil_file_dir)\n",
    "prework_df = pre_work_pipeline.transform(x)\n",
    "#Save to CSV so that we do not need to import and clean data everytime\n",
    "prework_df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "prework_df['Location'] = prework_df['Location'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>T_30cm</th>\n",
       "      <th>T_60cm</th>\n",
       "      <th>T_90cm</th>\n",
       "      <th>T_120cm</th>\n",
       "      <th>T_150cm</th>\n",
       "      <th>DATE_0</th>\n",
       "      <th>AWND_0</th>\n",
       "      <th>PGTM_0</th>\n",
       "      <th>...</th>\n",
       "      <th>RAIN_Y_N_1</th>\n",
       "      <th>RAIN_Y_N_2</th>\n",
       "      <th>RAIN_Y_N_3</th>\n",
       "      <th>RAIN_Y_N_4</th>\n",
       "      <th>RAIN_Y_N_5</th>\n",
       "      <th>RAIN_Y_N_6</th>\n",
       "      <th>RAIN_Y_N_7</th>\n",
       "      <th>RAIN_Y_N_8</th>\n",
       "      <th>RAIN_Y_N_9</th>\n",
       "      <th>RAIN_Y_N_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34470</th>\n",
       "      <td>CAF163</td>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>8.950</td>\n",
       "      <td>9.154</td>\n",
       "      <td>11.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.700</td>\n",
       "      <td>2015-11-06</td>\n",
       "      <td>9.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22692</th>\n",
       "      <td>CAF125</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>6.880</td>\n",
       "      <td>6.300</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.800</td>\n",
       "      <td>6.560</td>\n",
       "      <td>2013-04-11</td>\n",
       "      <td>10.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33962</th>\n",
       "      <td>CAF163</td>\n",
       "      <td>2014-06-16</td>\n",
       "      <td>13.980</td>\n",
       "      <td>12.370</td>\n",
       "      <td>11.52</td>\n",
       "      <td>10.800</td>\n",
       "      <td>10.300</td>\n",
       "      <td>2014-06-16</td>\n",
       "      <td>9.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62669</th>\n",
       "      <td>CAF314</td>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>2.267</td>\n",
       "      <td>4.121</td>\n",
       "      <td>6.30</td>\n",
       "      <td>8.108</td>\n",
       "      <td>9.679</td>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>15.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49231</th>\n",
       "      <td>CAF237</td>\n",
       "      <td>2007-10-05</td>\n",
       "      <td>10.230</td>\n",
       "      <td>12.920</td>\n",
       "      <td>13.49</td>\n",
       "      <td>13.640</td>\n",
       "      <td>13.720</td>\n",
       "      <td>2007-10-05</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1412.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67797</th>\n",
       "      <td>CAF351</td>\n",
       "      <td>2015-05-09</td>\n",
       "      <td>13.830</td>\n",
       "      <td>11.750</td>\n",
       "      <td>10.20</td>\n",
       "      <td>9.550</td>\n",
       "      <td>9.196</td>\n",
       "      <td>2015-05-09</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43182</th>\n",
       "      <td>CAF209</td>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>21.270</td>\n",
       "      <td>19.760</td>\n",
       "      <td>17.40</td>\n",
       "      <td>15.810</td>\n",
       "      <td>14.300</td>\n",
       "      <td>2014-08-06</td>\n",
       "      <td>4.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7727</th>\n",
       "      <td>CAF031</td>\n",
       "      <td>2015-02-21</td>\n",
       "      <td>5.862</td>\n",
       "      <td>5.892</td>\n",
       "      <td>6.30</td>\n",
       "      <td>6.700</td>\n",
       "      <td>6.200</td>\n",
       "      <td>2015-02-21</td>\n",
       "      <td>9.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24382</th>\n",
       "      <td>CAF129</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>2.770</td>\n",
       "      <td>4.620</td>\n",
       "      <td>5.40</td>\n",
       "      <td>5.200</td>\n",
       "      <td>6.500</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>4.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24175</th>\n",
       "      <td>CAF129</td>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>11.850</td>\n",
       "      <td>12.010</td>\n",
       "      <td>10.87</td>\n",
       "      <td>10.300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-07</td>\n",
       "      <td>7.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60844 rows × 183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location       Date  T_30cm  T_60cm  T_90cm  T_120cm  T_150cm  \\\n",
       "34470   CAF163 2015-11-06   8.950   9.154   11.54      NaN   12.700   \n",
       "22692   CAF125 2013-04-11   6.880   6.300    6.17    6.800    6.560   \n",
       "33962   CAF163 2014-06-16  13.980  12.370   11.52   10.800   10.300   \n",
       "62669   CAF314 2014-11-23   2.267   4.121    6.30    8.108    9.679   \n",
       "49231   CAF237 2007-10-05  10.230  12.920   13.49   13.640   13.720   \n",
       "...        ...        ...     ...     ...     ...      ...      ...   \n",
       "67797   CAF351 2015-05-09  13.830  11.750   10.20    9.550    9.196   \n",
       "43182   CAF209 2014-08-06  21.270  19.760   17.40   15.810   14.300   \n",
       "7727    CAF031 2015-02-21   5.862   5.892    6.30    6.700    6.200   \n",
       "24382   CAF129 2013-02-03   2.770   4.620    5.40    5.200    6.500   \n",
       "24175   CAF129 2012-06-07  11.850  12.010   10.87   10.300      NaN   \n",
       "\n",
       "          DATE_0  AWND_0  PGTM_0  ...  RAIN_Y_N_1  RAIN_Y_N_2  RAIN_Y_N_3  \\\n",
       "34470 2015-11-06    9.84     NaN  ...         1.0         0.0         0.0   \n",
       "22692 2013-04-11   10.51     NaN  ...         1.0         0.0         0.0   \n",
       "33962 2014-06-16    9.62     NaN  ...         0.0         1.0         1.0   \n",
       "62669 2014-11-23   15.88     NaN  ...         1.0         1.0         1.0   \n",
       "49231 2007-10-05    4.47  1412.0  ...         0.0         1.0         1.0   \n",
       "...          ...     ...     ...  ...         ...         ...         ...   \n",
       "67797 2015-05-09    4.03     NaN  ...         0.0         0.0         0.0   \n",
       "43182 2014-08-06    4.92     NaN  ...         0.0         0.0         0.0   \n",
       "7727  2015-02-21    9.17     NaN  ...         1.0         1.0         0.0   \n",
       "24382 2013-02-03    4.03     NaN  ...         0.0         0.0         0.0   \n",
       "24175 2012-06-07    7.16     NaN  ...         0.0         1.0         1.0   \n",
       "\n",
       "       RAIN_Y_N_4  RAIN_Y_N_5  RAIN_Y_N_6  RAIN_Y_N_7  RAIN_Y_N_8  RAIN_Y_N_9  \\\n",
       "34470         0.0         1.0         1.0         1.0         1.0         1.0   \n",
       "22692         1.0         1.0         1.0         1.0         0.0         0.0   \n",
       "33962         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "62669         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "49231         1.0         1.0         0.0         1.0         0.0         0.0   \n",
       "...           ...         ...         ...         ...         ...         ...   \n",
       "67797         0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "43182         1.0         0.0         0.0         0.0         0.0         0.0   \n",
       "7727          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "24382         1.0         1.0         1.0         0.0         1.0         1.0   \n",
       "24175         1.0         1.0         1.0         1.0         0.0         1.0   \n",
       "\n",
       "       RAIN_Y_N_10  \n",
       "34470          0.0  \n",
       "22692          0.0  \n",
       "33962          0.0  \n",
       "62669          0.0  \n",
       "49231          0.0  \n",
       "...            ...  \n",
       "67797          0.0  \n",
       "43182          0.0  \n",
       "7727           0.0  \n",
       "24382          1.0  \n",
       "24175          1.0  \n",
       "\n",
       "[60844 rows x 183 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First split out y values\n",
    "y_cols = ['VW_30cm', 'VW_60cm', 'VW_90cm', 'VW_120cm', 'VW_150cm']\n",
    "x_cols = [col for col in prework_df.columns if col not in y_cols]\n",
    "X = prework_df.loc[:, x_cols]\n",
    "y = prework_df.loc[:, y_cols]\n",
    "\n",
    "# Split training and test data\n",
    "# 80-20 ratio\n",
    "# Trying to keep same ratios for each location using stratify\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify = X['Location'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generic Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attribs = X_train.select_dtypes(exclude=['object', 'category', 'datetime64']).columns\n",
    "cat_attribs = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "date_attribs = ['Date']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value = 0)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "date_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(date_attribs)),\n",
    "        ('converter', Convert_Date())\n",
    "])\n",
    "\n",
    "data_prep_pipeline = FeatureUnion(transformer_list=[\n",
    "        ('num_pipeline', num_pipeline),\n",
    "        ('cat_pipeline', cat_pipeline),\n",
    "        ('date_pipeline', date_pipeline)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
